{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb02f578",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b11365b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🆕 No model found. Creating a new model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,472</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │ max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,616</span> │ max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18,876,416</span> │ max_pooling2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">37,750,784</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">8,389,632</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18,875,392</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,438,208</span> │ activation_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,719,104</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │ activation_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_21       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │            │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_22       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_23       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_4  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_5  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ activation_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_27       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_6  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_transpose… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,624</span> │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_28       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,320</span> │ activation_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv2d_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_29       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m24\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m3,472\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m2,320\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m4,640\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_3[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m1,180,160\u001b[0m │ max_pooling2d_4[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │  \u001b[38;5;34m4,719,616\u001b[0m │ max_pooling2d_5[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │  \u001b[38;5;34m9,438,208\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │ \u001b[38;5;34m18,876,416\u001b[0m │ max_pooling2d_6[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │ \u001b[38;5;34m37,750,784\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │      \u001b[38;5;34m8,192\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_15       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ activation_15[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │  \u001b[38;5;34m8,389,632\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m2048\u001b[0m)             │            │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │ \u001b[38;5;34m18,875,392\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_16       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │  \u001b[38;5;34m9,438,208\u001b[0m │ activation_16[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │      \u001b[38;5;34m4,096\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_17       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ activation_17[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m1024\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,097,664\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m1024\u001b[0m)             │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m4,719,104\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_18       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │  \u001b[38;5;34m2,359,808\u001b[0m │ activation_18[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │      \u001b[38;5;34m2,048\u001b[0m │ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_19       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_19[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m524,544\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │  \u001b[38;5;34m1,179,904\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_20       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ activation_20[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_21       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_21[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m131,200\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m256\u001b[0m)              │            │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m295,040\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_22       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_22[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_23       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_23[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_4  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m32,832\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m128\u001b[0m)              │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m73,792\u001b[0m │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_24       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_24[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_25       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_25[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_5  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m8,224\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m)               │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │     \u001b[38;5;34m18,464\u001b[0m │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_26       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ activation_26[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_27       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_27[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_transpose_6  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m2,064\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)   │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_transpose… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m32\u001b[0m)               │            │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_28 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m4,624\u001b[0m │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_28       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_29 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │      \u001b[38;5;34m2,320\u001b[0m │ activation_28[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │         \u001b[38;5;34m64\u001b[0m │ conv2d_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_29       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ activation_29[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_30 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │         \u001b[38;5;34m34\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,492,370</span> (474.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,492,370\u001b[0m (474.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,467,922</span> (474.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,467,922\u001b[0m (474.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,448</span> (95.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m24,448\u001b[0m (95.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x779e16ee5580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:42\u001b[0m 26s/step - accuracy: 0.1941 - loss: 1.6618 - mean_io_u_2: 0.4521 - per_class_iou: 0.0976 - precision_2: 0.1915 - recall_2: 0.9989"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 15:36:41.840302: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_5', 4 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_3', 8 bytes spill stores, 36 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_2', 8 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2083 - loss: 1.5714 - mean_io_u_2: 0.4497 - per_class_iou: 0.1058 - precision_2: 0.2012 - recall_2: 0.9993  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-25 15:36:57.556174: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_5', 4 bytes spill stores, 16 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_3', 8 bytes spill stores, 36 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'input_reduce_transpose_fusion_2', 8 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 1.31796, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8s/step - accuracy: 0.2158 - loss: 1.4966 - mean_io_u_2: 0.4492 - per_class_iou: 0.1108 - precision_2: 0.2029 - recall_2: 0.9995 - val_accuracy: 0.2212 - val_loss: 1.3180 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2767 - loss: 1.1495 - mean_io_u_2: 0.4496 - per_class_iou: 0.1560 - precision_2: 0.2015 - recall_2: 0.9998\n",
      "Epoch 2: val_loss improved from 1.31796 to 0.95688, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5s/step - accuracy: 0.2979 - loss: 1.0858 - mean_io_u_2: 0.4492 - per_class_iou: 0.1717 - precision_2: 0.2030 - recall_2: 0.9999 - val_accuracy: 0.2212 - val_loss: 0.9569 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4063 - loss: 0.8424 - mean_io_u_2: 0.4507 - per_class_iou: 0.2552 - precision_2: 0.1970 - recall_2: 1.0000\n",
      "Epoch 3: val_loss improved from 0.95688 to 0.73172, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5s/step - accuracy: 0.4455 - loss: 0.7883 - mean_io_u_2: 0.4493 - per_class_iou: 0.2861 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.7317 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5511 - loss: 0.6488 - mean_io_u_2: 0.4495 - per_class_iou: 0.3741 - precision_2: 0.2020 - recall_2: 1.0000\n",
      "Epoch 4: val_loss improved from 0.73172 to 0.61826, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5s/step - accuracy: 0.5715 - loss: 0.6254 - mean_io_u_2: 0.4493 - per_class_iou: 0.3919 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.6183 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6299 - loss: 0.5554 - mean_io_u_2: 0.4465 - per_class_iou: 0.4477 - precision_2: 0.2138 - recall_2: 1.0000\n",
      "Epoch 5: val_loss improved from 0.61826 to 0.57111, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6265 - loss: 0.5576 - mean_io_u_2: 0.4493 - per_class_iou: 0.4417 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.5711 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6450 - loss: 0.5442 - mean_io_u_2: 0.4512 - per_class_iou: 0.4568 - precision_2: 0.1952 - recall_2: 1.0000\n",
      "Epoch 6: val_loss improved from 0.57111 to 0.54585, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6588 - loss: 0.5336 - mean_io_u_2: 0.4493 - per_class_iou: 0.4725 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.5459 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6672 - loss: 0.5255 - mean_io_u_2: 0.4498 - per_class_iou: 0.4800 - precision_2: 0.2009 - recall_2: 1.0000\n",
      "Epoch 7: val_loss improved from 0.54585 to 0.52735, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6724 - loss: 0.5210 - mean_io_u_2: 0.4493 - per_class_iou: 0.4858 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.5274 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6786 - loss: 0.5121 - mean_io_u_2: 0.4493 - per_class_iou: 0.4918 - precision_2: 0.2027 - recall_2: 1.0000\n",
      "Epoch 8: val_loss improved from 0.52735 to 0.51161, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6835 - loss: 0.5093 - mean_io_u_2: 0.4493 - per_class_iou: 0.4969 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.5116 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6784 - loss: 0.5073 - mean_io_u_2: 0.4509 - per_class_iou: 0.4895 - precision_2: 0.1965 - recall_2: 1.0000\n",
      "Epoch 9: val_loss improved from 0.51161 to 0.49924, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6872 - loss: 0.4990 - mean_io_u_2: 0.4493 - per_class_iou: 0.5005 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4992 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6973 - loss: 0.4924 - mean_io_u_2: 0.4493 - per_class_iou: 0.5108 - precision_2: 0.2030 - recall_2: 1.0000\n",
      "Epoch 10: val_loss improved from 0.49924 to 0.48986, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.6934 - loss: 0.4913 - mean_io_u_2: 0.4493 - per_class_iou: 0.5068 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4899 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6564 - loss: 0.4960 - mean_io_u_2: 0.4514 - per_class_iou: 0.4676 - precision_2: 0.1945 - recall_2: 1.0000\n",
      "Epoch 11: val_loss improved from 0.48986 to 0.48265, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6718 - loss: 0.4868 - mean_io_u_2: 0.4493 - per_class_iou: 0.4852 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4827 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6919 - loss: 0.4828 - mean_io_u_2: 0.4490 - per_class_iou: 0.5056 - precision_2: 0.2040 - recall_2: 1.0000\n",
      "Epoch 12: val_loss improved from 0.48265 to 0.47883, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6910 - loss: 0.4832 - mean_io_u_2: 0.4493 - per_class_iou: 0.5044 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4788 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6856 - loss: 0.4846 - mean_io_u_2: 0.4501 - per_class_iou: 0.4978 - precision_2: 0.1997 - recall_2: 1.0000\n",
      "Epoch 13: val_loss improved from 0.47883 to 0.47633, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6899 - loss: 0.4810 - mean_io_u_2: 0.4493 - per_class_iou: 0.5033 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4763 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6916 - loss: 0.4730 - mean_io_u_2: 0.4474 - per_class_iou: 0.5076 - precision_2: 0.2102 - recall_2: 1.0000\n",
      "Epoch 14: val_loss improved from 0.47633 to 0.47406, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.6829 - loss: 0.4795 - mean_io_u_2: 0.4493 - per_class_iou: 0.4962 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4741 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7084 - loss: 0.4690 - mean_io_u_2: 0.4469 - per_class_iou: 0.5257 - precision_2: 0.2126 - recall_2: 1.0000\n",
      "Epoch 15: val_loss improved from 0.47406 to 0.47262, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6990 - loss: 0.4779 - mean_io_u_2: 0.4493 - per_class_iou: 0.5125 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4726 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6730 - loss: 0.4890 - mean_io_u_2: 0.4523 - per_class_iou: 0.4822 - precision_2: 0.1906 - recall_2: 1.0000\n",
      "Epoch 16: val_loss improved from 0.47262 to 0.47106, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6899 - loss: 0.4768 - mean_io_u_2: 0.4493 - per_class_iou: 0.5033 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4711 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7088 - loss: 0.4748 - mean_io_u_2: 0.4490 - per_class_iou: 0.5232 - precision_2: 0.2041 - recall_2: 1.0000\n",
      "Epoch 17: val_loss improved from 0.47106 to 0.46972, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7057 - loss: 0.4757 - mean_io_u_2: 0.4493 - per_class_iou: 0.5194 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4697 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7033 - loss: 0.4741 - mean_io_u_2: 0.4490 - per_class_iou: 0.5174 - precision_2: 0.2040 - recall_2: 1.0000\n",
      "Epoch 18: val_loss improved from 0.46972 to 0.46902, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6982 - loss: 0.4751 - mean_io_u_2: 0.4493 - per_class_iou: 0.5118 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4690 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7053 - loss: 0.4688 - mean_io_u_2: 0.4478 - per_class_iou: 0.5210 - precision_2: 0.2087 - recall_2: 1.0000\n",
      "Epoch 19: val_loss improved from 0.46902 to 0.46781, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7072 - loss: 0.4744 - mean_io_u_2: 0.4493 - per_class_iou: 0.5210 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4678 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7082 - loss: 0.4628 - mean_io_u_2: 0.4464 - per_class_iou: 0.5262 - precision_2: 0.2144 - recall_2: 1.0000\n",
      "Epoch 20: val_loss improved from 0.46781 to 0.46621, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6943 - loss: 0.4736 - mean_io_u_2: 0.4493 - per_class_iou: 0.5077 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4662 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6792 - loss: 0.4771 - mean_io_u_2: 0.4502 - per_class_iou: 0.4913 - precision_2: 0.1992 - recall_2: 1.0000\n",
      "Epoch 21: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6625 - loss: 0.4733 - mean_io_u_2: 0.4493 - per_class_iou: 0.4761 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4674 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6778 - loss: 0.4761 - mean_io_u_2: 0.4501 - per_class_iou: 0.4900 - precision_2: 0.1995 - recall_2: 1.0000\n",
      "Epoch 22: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6818 - loss: 0.4729 - mean_io_u_2: 0.4493 - per_class_iou: 0.4951 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4681 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6713 - loss: 0.4791 - mean_io_u_2: 0.4510 - per_class_iou: 0.4824 - precision_2: 0.1961 - recall_2: 1.0000\n",
      "Epoch 23: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6809 - loss: 0.4725 - mean_io_u_2: 0.4493 - per_class_iou: 0.4942 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4692 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6929 - loss: 0.4671 - mean_io_u_2: 0.4479 - per_class_iou: 0.5082 - precision_2: 0.2083 - recall_2: 1.0000\n",
      "Epoch 24: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6882 - loss: 0.4722 - mean_io_u_2: 0.4493 - per_class_iou: 0.5016 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4695 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6776 - loss: 0.4820 - mean_io_u_2: 0.4518 - per_class_iou: 0.4875 - precision_2: 0.1928 - recall_2: 1.0000\n",
      "Epoch 25: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6881 - loss: 0.4720 - mean_io_u_2: 0.4493 - per_class_iou: 0.5015 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4691 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6980 - loss: 0.4650 - mean_io_u_2: 0.4475 - per_class_iou: 0.5140 - precision_2: 0.2101 - recall_2: 1.0000\n",
      "Epoch 26: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6898 - loss: 0.4717 - mean_io_u_2: 0.4493 - per_class_iou: 0.5031 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4680 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6960 - loss: 0.4701 - mean_io_u_2: 0.4489 - per_class_iou: 0.5100 - precision_2: 0.2046 - recall_2: 1.0000\n",
      "Epoch 27: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6954 - loss: 0.4718 - mean_io_u_2: 0.4493 - per_class_iou: 0.5089 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4674 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7063 - loss: 0.4652 - mean_io_u_2: 0.4477 - per_class_iou: 0.5223 - precision_2: 0.2094 - recall_2: 1.0000\n",
      "Epoch 28: val_loss did not improve from 0.46621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7014 - loss: 0.4715 - mean_io_u_2: 0.4493 - per_class_iou: 0.5150 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4666 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7075 - loss: 0.4659 - mean_io_u_2: 0.4478 - per_class_iou: 0.5234 - precision_2: 0.2088 - recall_2: 1.0000\n",
      "Epoch 29: val_loss improved from 0.46621 to 0.46594, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7012 - loss: 0.4715 - mean_io_u_2: 0.4493 - per_class_iou: 0.5149 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4659 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6987 - loss: 0.4687 - mean_io_u_2: 0.4486 - per_class_iou: 0.5131 - precision_2: 0.2055 - recall_2: 1.0000\n",
      "Epoch 30: val_loss improved from 0.46594 to 0.46512, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.7005 - loss: 0.4712 - mean_io_u_2: 0.4493 - per_class_iou: 0.5141 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4651 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7088 - loss: 0.4735 - mean_io_u_2: 0.4498 - per_class_iou: 0.5218 - precision_2: 0.2006 - recall_2: 1.0000\n",
      "Epoch 31: val_loss improved from 0.46512 to 0.46419, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7102 - loss: 0.4713 - mean_io_u_2: 0.4493 - per_class_iou: 0.5241 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4642 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7044 - loss: 0.4711 - mean_io_u_2: 0.4493 - per_class_iou: 0.5181 - precision_2: 0.2029 - recall_2: 1.0000\n",
      "Epoch 32: val_loss improved from 0.46419 to 0.46357, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7077 - loss: 0.4710 - mean_io_u_2: 0.4493 - per_class_iou: 0.5215 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4636 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7041 - loss: 0.4696 - mean_io_u_2: 0.4489 - per_class_iou: 0.5182 - precision_2: 0.2043 - recall_2: 1.0000\n",
      "Epoch 33: val_loss improved from 0.46357 to 0.46312, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7053 - loss: 0.4709 - mean_io_u_2: 0.4493 - per_class_iou: 0.5191 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4631 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6960 - loss: 0.4798 - mean_io_u_2: 0.4516 - per_class_iou: 0.5061 - precision_2: 0.1937 - recall_2: 1.0000\n",
      "Epoch 34: val_loss improved from 0.46312 to 0.46261, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7071 - loss: 0.4710 - mean_io_u_2: 0.4493 - per_class_iou: 0.5209 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4626 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7150 - loss: 0.4628 - mean_io_u_2: 0.4472 - per_class_iou: 0.5323 - precision_2: 0.2112 - recall_2: 1.0000\n",
      "Epoch 35: val_loss improved from 0.46261 to 0.46198, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7017 - loss: 0.4709 - mean_io_u_2: 0.4493 - per_class_iou: 0.5153 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4620 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6938 - loss: 0.4742 - mean_io_u_2: 0.4502 - per_class_iou: 0.5060 - precision_2: 0.1993 - recall_2: 1.0000\n",
      "Epoch 36: val_loss improved from 0.46198 to 0.46133, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.6982 - loss: 0.4707 - mean_io_u_2: 0.4493 - per_class_iou: 0.5118 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4613 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7022 - loss: 0.4732 - mean_io_u_2: 0.4499 - per_class_iou: 0.5150 - precision_2: 0.2005 - recall_2: 1.0000\n",
      "Epoch 37: val_loss improved from 0.46133 to 0.46106, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7083 - loss: 0.4707 - mean_io_u_2: 0.4493 - per_class_iou: 0.5222 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4611 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7146 - loss: 0.4707 - mean_io_u_2: 0.4493 - per_class_iou: 0.5287 - precision_2: 0.2028 - recall_2: 1.0000\n",
      "Epoch 38: val_loss improved from 0.46106 to 0.46080, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7124 - loss: 0.4706 - mean_io_u_2: 0.4493 - per_class_iou: 0.5264 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4608 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7140 - loss: 0.4727 - mean_io_u_2: 0.4498 - per_class_iou: 0.5273 - precision_2: 0.2006 - recall_2: 1.0000\n",
      "Epoch 39: val_loss improved from 0.46080 to 0.46039, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.7152 - loss: 0.4704 - mean_io_u_2: 0.4493 - per_class_iou: 0.5294 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4604 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7219 - loss: 0.4643 - mean_io_u_2: 0.4476 - per_class_iou: 0.5391 - precision_2: 0.2096 - recall_2: 1.0000\n",
      "Epoch 40: val_loss improved from 0.46039 to 0.46001, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7141 - loss: 0.4708 - mean_io_u_2: 0.4493 - per_class_iou: 0.5282 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4600 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6964 - loss: 0.4796 - mean_io_u_2: 0.4515 - per_class_iou: 0.5065 - precision_2: 0.1938 - recall_2: 1.0000\n",
      "Epoch 41: val_loss improved from 0.46001 to 0.45966, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7062 - loss: 0.4705 - mean_io_u_2: 0.4493 - per_class_iou: 0.5200 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4597 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7051 - loss: 0.4713 - mean_io_u_2: 0.4495 - per_class_iou: 0.5185 - precision_2: 0.2019 - recall_2: 1.0000\n",
      "Epoch 42: val_loss improved from 0.45966 to 0.45941, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7117 - loss: 0.4704 - mean_io_u_2: 0.4493 - per_class_iou: 0.5257 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4594 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7140 - loss: 0.4725 - mean_io_u_2: 0.4499 - per_class_iou: 0.5272 - precision_2: 0.2005 - recall_2: 1.0000\n",
      "Epoch 43: val_loss improved from 0.45941 to 0.45908, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.7160 - loss: 0.4702 - mean_io_u_2: 0.4493 - per_class_iou: 0.5302 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4591 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7035 - loss: 0.4655 - mean_io_u_2: 0.4481 - per_class_iou: 0.5189 - precision_2: 0.2078 - recall_2: 1.0000\n",
      "Epoch 44: val_loss improved from 0.45908 to 0.45826, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6961 - loss: 0.4703 - mean_io_u_2: 0.4493 - per_class_iou: 0.5096 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4583 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6920 - loss: 0.4783 - mean_io_u_2: 0.4514 - per_class_iou: 0.5024 - precision_2: 0.1944 - recall_2: 1.0000\n",
      "Epoch 45: val_loss improved from 0.45826 to 0.45775, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7062 - loss: 0.4700 - mean_io_u_2: 0.4493 - per_class_iou: 0.5200 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4578 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7109 - loss: 0.4734 - mean_io_u_2: 0.4502 - per_class_iou: 0.5236 - precision_2: 0.1993 - recall_2: 1.0000\n",
      "Epoch 46: val_loss improved from 0.45775 to 0.45762, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7162 - loss: 0.4699 - mean_io_u_2: 0.4493 - per_class_iou: 0.5305 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4576 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7170 - loss: 0.4703 - mean_io_u_2: 0.4494 - per_class_iou: 0.5311 - precision_2: 0.2025 - recall_2: 1.0000\n",
      "Epoch 47: val_loss improved from 0.45762 to 0.45750, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7175 - loss: 0.4699 - mean_io_u_2: 0.4493 - per_class_iou: 0.5318 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4575 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7223 - loss: 0.4684 - mean_io_u_2: 0.4488 - per_class_iou: 0.5377 - precision_2: 0.2047 - recall_2: 1.0000\n",
      "Epoch 48: val_loss improved from 0.45750 to 0.45740, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7190 - loss: 0.4699 - mean_io_u_2: 0.4493 - per_class_iou: 0.5334 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4574 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7222 - loss: 0.4645 - mean_io_u_2: 0.4479 - per_class_iou: 0.5388 - precision_2: 0.2083 - recall_2: 1.0000\n",
      "Epoch 49: val_loss improved from 0.45740 to 0.45727, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7131 - loss: 0.4698 - mean_io_u_2: 0.4493 - per_class_iou: 0.5272 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4573 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7042 - loss: 0.4727 - mean_io_u_2: 0.4501 - per_class_iou: 0.5168 - precision_2: 0.1997 - recall_2: 1.0000\n",
      "Epoch 50: val_loss improved from 0.45727 to 0.45700, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7129 - loss: 0.4696 - mean_io_u_2: 0.4493 - per_class_iou: 0.5270 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4570 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7305 - loss: 0.4621 - mean_io_u_2: 0.4473 - per_class_iou: 0.5487 - precision_2: 0.2108 - recall_2: 1.0000\n",
      "Epoch 51: val_loss improved from 0.45700 to 0.45692, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7220 - loss: 0.4698 - mean_io_u_2: 0.4493 - per_class_iou: 0.5366 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4569 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7277 - loss: 0.4659 - mean_io_u_2: 0.4482 - per_class_iou: 0.5446 - precision_2: 0.2072 - recall_2: 1.0000\n",
      "Epoch 52: val_loss improved from 0.45692 to 0.45666, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7187 - loss: 0.4699 - mean_io_u_2: 0.4493 - per_class_iou: 0.5331 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4567 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7310 - loss: 0.4626 - mean_io_u_2: 0.4475 - per_class_iou: 0.5491 - precision_2: 0.2101 - recall_2: 1.0000\n",
      "Epoch 53: val_loss improved from 0.45666 to 0.45646, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7244 - loss: 0.4694 - mean_io_u_2: 0.4493 - per_class_iou: 0.5392 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4565 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7375 - loss: 0.4634 - mean_io_u_2: 0.4477 - per_class_iou: 0.5558 - precision_2: 0.2092 - recall_2: 1.0000\n",
      "Epoch 54: val_loss did not improve from 0.45646\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7279 - loss: 0.4693 - mean_io_u_2: 0.4493 - per_class_iou: 0.5429 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4565 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7236 - loss: 0.4693 - mean_io_u_2: 0.4492 - per_class_iou: 0.5383 - precision_2: 0.2030 - recall_2: 1.0000\n",
      "Epoch 55: val_loss improved from 0.45646 to 0.45621, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7231 - loss: 0.4693 - mean_io_u_2: 0.4493 - per_class_iou: 0.5378 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4562 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7128 - loss: 0.4838 - mean_io_u_2: 0.4529 - per_class_iou: 0.5212 - precision_2: 0.1884 - recall_2: 1.0000\n",
      "Epoch 56: val_loss did not improve from 0.45621\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7273 - loss: 0.4695 - mean_io_u_2: 0.4493 - per_class_iou: 0.5423 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4562 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7298 - loss: 0.4633 - mean_io_u_2: 0.4477 - per_class_iou: 0.5473 - precision_2: 0.2091 - recall_2: 1.0000\n",
      "Epoch 57: val_loss improved from 0.45621 to 0.45611, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.7240 - loss: 0.4692 - mean_io_u_2: 0.4493 - per_class_iou: 0.5388 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4561 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7253 - loss: 0.4676 - mean_io_u_2: 0.4489 - per_class_iou: 0.5408 - precision_2: 0.2046 - recall_2: 1.0000\n",
      "Epoch 58: val_loss improved from 0.45611 to 0.45605, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7256 - loss: 0.4692 - mean_io_u_2: 0.4493 - per_class_iou: 0.5405 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4561 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7125 - loss: 0.4742 - mean_io_u_2: 0.4506 - per_class_iou: 0.5246 - precision_2: 0.1977 - recall_2: 1.0000\n",
      "Epoch 59: val_loss improved from 0.45605 to 0.45586, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.7178 - loss: 0.4690 - mean_io_u_2: 0.4493 - per_class_iou: 0.5321 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4559 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7221 - loss: 0.4698 - mean_io_u_2: 0.4495 - per_class_iou: 0.5364 - precision_2: 0.2021 - recall_2: 1.0000\n",
      "Epoch 60: val_loss improved from 0.45586 to 0.45580, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7279 - loss: 0.4690 - mean_io_u_2: 0.4493 - per_class_iou: 0.5430 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4558 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6921 - loss: 0.4769 - mean_io_u_2: 0.4513 - per_class_iou: 0.5026 - precision_2: 0.1947 - recall_2: 1.0000\n",
      "Epoch 61: val_loss did not improve from 0.45580\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6920 - loss: 0.4690 - mean_io_u_2: 0.4493 - per_class_iou: 0.5054 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4560 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7123 - loss: 0.4589 - mean_io_u_2: 0.4466 - per_class_iou: 0.5301 - precision_2: 0.2138 - recall_2: 1.0000\n",
      "Epoch 62: val_loss did not improve from 0.45580\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7134 - loss: 0.4690 - mean_io_u_2: 0.4493 - per_class_iou: 0.5275 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4558 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7350 - loss: 0.4620 - mean_io_u_2: 0.4475 - per_class_iou: 0.5534 - precision_2: 0.2100 - recall_2: 1.0000\n",
      "Epoch 63: val_loss improved from 0.45580 to 0.45554, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7235 - loss: 0.4688 - mean_io_u_2: 0.4493 - per_class_iou: 0.5382 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4555 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7240 - loss: 0.4617 - mean_io_u_2: 0.4474 - per_class_iou: 0.5415 - precision_2: 0.2103 - recall_2: 1.0000\n",
      "Epoch 64: val_loss improved from 0.45554 to 0.45535, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7195 - loss: 0.4688 - mean_io_u_2: 0.4493 - per_class_iou: 0.5340 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4553 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7275 - loss: 0.4634 - mean_io_u_2: 0.4478 - per_class_iou: 0.5447 - precision_2: 0.2087 - recall_2: 1.0000\n",
      "Epoch 65: val_loss improved from 0.45535 to 0.45519, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7235 - loss: 0.4688 - mean_io_u_2: 0.4493 - per_class_iou: 0.5382 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4552 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7297 - loss: 0.4655 - mean_io_u_2: 0.4484 - per_class_iou: 0.5462 - precision_2: 0.2063 - recall_2: 1.0000\n",
      "Epoch 66: val_loss improved from 0.45519 to 0.45508, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7255 - loss: 0.4689 - mean_io_u_2: 0.4493 - per_class_iou: 0.5403 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4551 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7111 - loss: 0.4741 - mean_io_u_2: 0.4507 - per_class_iou: 0.5230 - precision_2: 0.1974 - recall_2: 1.0000\n",
      "Epoch 67: val_loss improved from 0.45508 to 0.45498, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7207 - loss: 0.4687 - mean_io_u_2: 0.4493 - per_class_iou: 0.5352 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4550 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7349 - loss: 0.4601 - mean_io_u_2: 0.4470 - per_class_iou: 0.5541 - precision_2: 0.2120 - recall_2: 1.0000\n",
      "Epoch 68: val_loss improved from 0.45498 to 0.45481, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7265 - loss: 0.4687 - mean_io_u_2: 0.4493 - per_class_iou: 0.5414 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4548 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7396 - loss: 0.4601 - mean_io_u_2: 0.4470 - per_class_iou: 0.5591 - precision_2: 0.2120 - recall_2: 1.0000\n",
      "Epoch 69: val_loss improved from 0.45481 to 0.45468, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7287 - loss: 0.4689 - mean_io_u_2: 0.4493 - per_class_iou: 0.5438 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4547 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7114 - loss: 0.4804 - mean_io_u_2: 0.4522 - per_class_iou: 0.5208 - precision_2: 0.1910 - recall_2: 1.0000\n",
      "Epoch 70: val_loss did not improve from 0.45468\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7264 - loss: 0.4687 - mean_io_u_2: 0.4493 - per_class_iou: 0.5413 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4547 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7335 - loss: 0.4641 - mean_io_u_2: 0.4481 - per_class_iou: 0.5508 - precision_2: 0.2075 - recall_2: 1.0000\n",
      "Epoch 71: val_loss improved from 0.45468 to 0.45462, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7273 - loss: 0.4685 - mean_io_u_2: 0.4493 - per_class_iou: 0.5423 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4546 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7229 - loss: 0.4736 - mean_io_u_2: 0.4505 - per_class_iou: 0.5357 - precision_2: 0.1980 - recall_2: 1.0000\n",
      "Epoch 72: val_loss improved from 0.45462 to 0.45446, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.7271 - loss: 0.4687 - mean_io_u_2: 0.4493 - per_class_iou: 0.5420 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4545 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7276 - loss: 0.4717 - mean_io_u_2: 0.4500 - per_class_iou: 0.5415 - precision_2: 0.2001 - recall_2: 1.0000\n",
      "Epoch 73: val_loss improved from 0.45446 to 0.45427, saving model to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.7275 - loss: 0.4689 - mean_io_u_2: 0.4493 - per_class_iou: 0.5425 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4543 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7285 - loss: 0.4671 - mean_io_u_2: 0.4488 - per_class_iou: 0.5442 - precision_2: 0.2047 - recall_2: 1.0000\n",
      "Epoch 74: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7276 - loss: 0.4687 - mean_io_u_2: 0.4493 - per_class_iou: 0.5426 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4543 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7291 - loss: 0.4778 - mean_io_u_2: 0.4516 - per_class_iou: 0.5404 - precision_2: 0.1935 - recall_2: 1.0000\n",
      "Epoch 75: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7373 - loss: 0.4686 - mean_io_u_2: 0.4493 - per_class_iou: 0.5532 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4544 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7356 - loss: 0.4661 - mean_io_u_2: 0.4487 - per_class_iou: 0.5523 - precision_2: 0.2054 - recall_2: 1.0000\n",
      "Epoch 76: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7293 - loss: 0.4686 - mean_io_u_2: 0.4493 - per_class_iou: 0.5445 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4544 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7224 - loss: 0.4752 - mean_io_u_2: 0.4509 - per_class_iou: 0.5344 - precision_2: 0.1962 - recall_2: 1.0000\n",
      "Epoch 77: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7337 - loss: 0.4687 - mean_io_u_2: 0.4493 - per_class_iou: 0.5492 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4545 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 78/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7333 - loss: 0.4735 - mean_io_u_2: 0.4506 - per_class_iou: 0.5468 - precision_2: 0.1978 - recall_2: 1.0000\n",
      "Epoch 78: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7413 - loss: 0.4684 - mean_io_u_2: 0.4493 - per_class_iou: 0.5576 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4544 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7389 - loss: 0.4731 - mean_io_u_2: 0.4504 - per_class_iou: 0.5531 - precision_2: 0.1984 - recall_2: 1.0000\n",
      "Epoch 79: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7418 - loss: 0.4686 - mean_io_u_2: 0.4493 - per_class_iou: 0.5581 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4545 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7442 - loss: 0.4612 - mean_io_u_2: 0.4474 - per_class_iou: 0.5637 - precision_2: 0.2105 - recall_2: 1.0000\n",
      "Epoch 80: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7367 - loss: 0.4686 - mean_io_u_2: 0.4493 - per_class_iou: 0.5525 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4545 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7472 - loss: 0.4652 - mean_io_u_2: 0.4485 - per_class_iou: 0.5654 - precision_2: 0.2062 - recall_2: 1.0000\n",
      "Epoch 81: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7394 - loss: 0.4683 - mean_io_u_2: 0.4493 - per_class_iou: 0.5554 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2212 - val_loss: 0.4545 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1106 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7415 - loss: 0.4690 - mean_io_u_2: 0.4493 - per_class_iou: 0.5578 - precision_2: 0.2026 - recall_2: 1.0000\n",
      "Epoch 82: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7411 - loss: 0.4688 - mean_io_u_2: 0.4493 - per_class_iou: 0.5573 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2219 - val_loss: 0.4544 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1111 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7544 - loss: 0.4593 - mean_io_u_2: 0.4468 - per_class_iou: 0.5763 - precision_2: 0.2128 - recall_2: 1.0000\n",
      "Epoch 83: val_loss did not improve from 0.45427\n",
      "val_mean_io_u not found in logs.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7411 - loss: 0.4686 - mean_io_u_2: 0.4493 - per_class_iou: 0.5574 - precision_2: 0.2030 - recall_2: 1.0000 - val_accuracy: 0.2235 - val_loss: 0.4544 - val_mean_io_u_2: 0.4447 - val_per_class_iou: 0.1123 - val_precision_2: 0.2212 - val_recall_2: 1.0000 - learning_rate: 1.5625e-05\n",
      "Epoch 83: early stopping\n",
      "Restoring model weights from the end of the best epoch: 73.\n",
      "Training model completed.\n",
      "Model saved to /home/dibakar88/Dibakar/unetpp_model.keras\n",
      "Processing: InputTitle0.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting patches: 100%|██████████| 30276/30276 [19:38<00:00, 25.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/dibakar88/Dibakar/result/InputTitle0_predicted.tif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"UNET_chatGPT_V3.3.2\n",
    "\n",
    "Automatically generated by Colab.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1krymnzYHr8CGWPj17a1LwnBE6FbA7sVh\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "#os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir=/home/trung/cuda-12.3/nvvm/libdevice\"\n",
    "\n",
    "os.environ[\"XLA_FLAGS\"] = \"/home/dibakar88/myenv\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import tifffile as tiff\n",
    "import csv\n",
    "\n",
    "import rasterio\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set GPU memory growth to avoid RAM overload\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "\n",
    "def get_npy_filepaths(img_dir, mask_dir):\n",
    "    img_files = sorted([os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith('.npy')])\n",
    "    mask_files = sorted([os.path.join(mask_dir, f) for f in os.listdir(mask_dir) if f.endswith('.npy')])\n",
    "    return shuffle(img_files, mask_files, random_state=42)\n",
    "\n",
    "def parse_image_mask(img_path, mask_path):\n",
    "    def _load_npy(img, mask):\n",
    "        img = img.decode(\"utf-8\")\n",
    "        mask = mask.decode(\"utf-8\")\n",
    "\n",
    "        img_arr = np.load(img).astype('float32')\n",
    "        mask_arr = np.load(mask).astype('int32')\n",
    "       \n",
    "\n",
    "        # Handle mask shape\n",
    "        if mask_arr.ndim == 3:\n",
    "            mask_arr = mask_arr[:, :, 0]  # squeeze out extra dim if needed\n",
    "\n",
    "\n",
    "        valid_mask = (mask_arr >= 0) & (mask_arr < NUM_CLASSES)\n",
    "\n",
    "        clipped_mask = np.where(valid_mask, mask_arr, 0)  # temporarily set 255 to 0\n",
    "        mask_arr = to_categorical(clipped_mask, num_classes=NUM_CLASSES).astype('float32')\n",
    "\n",
    "\n",
    "        # Zero out invalid pixels (255) in the one-hot encoded mask\n",
    "        mask_arr *= np.expand_dims(valid_mask, axis=-1)\n",
    "\n",
    "        return img_arr, mask_arr\n",
    "\n",
    "    img, mask = tf.numpy_function(_load_npy, [img_path, mask_path], [tf.float32, tf.float32])\n",
    "    img.set_shape((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    mask.set_shape((IMG_HEIGHT, IMG_WIDTH, NUM_CLASSES))\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "def create_dataset(img_paths, mask_paths, batch_size=16, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, mask_paths))\n",
    "    dataset = dataset.map(parse_image_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def unetpp_model_tf(input_shape, num_classes, l2_factor=1e-4):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    def conv_block(x, filters, dropout_rate=0.3):\n",
    "        x = tf.keras.layers.Conv2D(filters, 3, padding='same',\n",
    "                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        x = tf.keras.layers.Conv2D(filters, 3, padding='same',\n",
    "                                   kernel_regularizer=tf.keras.regularizers.l2(l2_factor))(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "        return x\n",
    "\n",
    "    def upsample_concat(x, skip):\n",
    "        x = tf.keras.layers.Conv2DTranspose(tf.keras.backend.int_shape(skip)[-1], 2, strides=2, padding='same')(x)\n",
    "        return tf.keras.layers.concatenate([x, skip])\n",
    "\n",
    "    # Encoder path (8 levels)\n",
    "    x00 = conv_block(inputs, 16, 0.1)\n",
    "    p0 = tf.keras.layers.MaxPooling2D()(x00)\n",
    "\n",
    "    x10 = conv_block(p0, 32, 0.12)\n",
    "    p1 = tf.keras.layers.MaxPooling2D()(x10)\n",
    "\n",
    "    x20 = conv_block(p1, 64, 0.15)\n",
    "    p2 = tf.keras.layers.MaxPooling2D()(x20)\n",
    "\n",
    "    x30 = conv_block(p2, 128, 0.18)\n",
    "    p3 = tf.keras.layers.MaxPooling2D()(x30)\n",
    "\n",
    "    x40 = conv_block(p3, 256, 0.20)\n",
    "    p4 = tf.keras.layers.MaxPooling2D()(x40)\n",
    "\n",
    "    x50 = conv_block(p4, 512, 0.25)\n",
    "    p5 = tf.keras.layers.MaxPooling2D()(x50)\n",
    "\n",
    "    x60 = conv_block(p5, 1024, 0.30)\n",
    "    p6 = tf.keras.layers.MaxPooling2D()(x60)\n",
    "\n",
    "    x70 = conv_block(p6, 2048, 0.35)  # bottleneck\n",
    "\n",
    "    # Decoder with nested connections (partial, expand as needed)\n",
    "    x61 = conv_block(upsample_concat(x70, x60), 1024, 0.3)\n",
    "    x51 = conv_block(upsample_concat(x61, x50), 512, 0.25)\n",
    "    x41 = conv_block(upsample_concat(x51, x40), 256, 0.20)\n",
    "    x31 = conv_block(upsample_concat(x41, x30), 128, 0.18)\n",
    "    x21 = conv_block(upsample_concat(x31, x20), 64, 0.15)\n",
    "    x11 = conv_block(upsample_concat(x21, x10), 32, 0.12)\n",
    "    x01 = conv_block(upsample_concat(x11, x00), 16, 0.1)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, 1, activation='softmax')(x01)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def classify_full_image(image_path, model, patch_size=128, stride=32):\n",
    "    img = tiff.imread(image_path)  # shape: (H, W, Bands)i\n",
    "    H, W, C = img.shape\n",
    "    prob_map = np.zeros((H, W, model.output_shape[-1]), dtype=np.float32)\n",
    "    count_map = np.zeros((H, W, 1), dtype=np.float32)\n",
    "\n",
    "    # Calculate total number of steps for progress bar\n",
    "    total_steps = ((H - 1) // stride + 1) * ((W - 1) // stride + 1)\n",
    "    pbar = tqdm(total=total_steps, desc=\"Predicting patches\")\n",
    "\n",
    "\n",
    "    for i in range(0,H, stride):\n",
    "        for j in range(0, W , stride):\n",
    "            i_start = min(i, H - patch_size)\n",
    "            j_start = min(j, W - patch_size)\n",
    "            \n",
    "            patch = img[i_start:i_start+patch_size, j_start:j_start+patch_size, :]\n",
    "            patch = patch.astype('float32')\n",
    "            patch = np.nan_to_num(patch, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            \n",
    "            \n",
    "            pred = model.predict(patch[np.newaxis, ...],verbose=0)[0]  # shape: (patch_size, patch_size, num_classes)\n",
    "\n",
    "            prob_map[i_start:i_start+patch_size, j_start:j_start+patch_size, :] += pred\n",
    "            count_map[i_start:i_start+patch_size, j_start:j_start+patch_size, :] += 1\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    # Avoid division by zero\n",
    "    count_map[count_map == 0] = 1\n",
    "    prob_map /= count_map\n",
    "    prediction_map = np.argmax(prob_map, axis=-1).astype(np.uint8)\n",
    "    return prediction_map\n",
    "\n",
    "def save_classified_geotiff(classified_array, reference_path, output_path):\n",
    "    # Use a reference Sentinel-1 image for geo info\n",
    "    with rasterio.open(reference_path) as src:\n",
    "        profile = src.profile\n",
    "        profile.update({\n",
    "            'count': 1,\n",
    "            'dtype': 'uint8',  # change based on your class dtype\n",
    "            'compress': 'lzw'\n",
    "        })\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(classified_array.astype('byte'), 1)\n",
    "\n",
    "def track_class_counts(dataset, num_classes):\n",
    "    class_counts = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    def generator():\n",
    "        for x_batch, y_batch in dataset:\n",
    "            y_np = y_batch.numpy()\n",
    "            batch_counts = np.sum(y_np, axis=(0, 1, 2))  # One-hot format\n",
    "            class_counts[:] += batch_counts.astype(np.int64)\n",
    "            yield x_batch, y_batch\n",
    "\n",
    "    for sample_x, sample_y in dataset.take(1):\n",
    "        x_spec = tf.TensorSpec(sample_x.shape, sample_x.dtype)\n",
    "        y_spec = tf.TensorSpec(sample_y.shape, sample_y.dtype)\n",
    "        break\n",
    "\n",
    "    tracked_dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(x_spec, y_spec)\n",
    "    )\n",
    "\n",
    "    return tracked_dataset, class_counts\n",
    "\n",
    "class DynamicWeightsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, class_counts, smoothing=1.0):\n",
    "        super().__init__()\n",
    "        self.class_counts = class_counts\n",
    "        self.smoothing = smoothing\n",
    "        self.weights = self._compute_weights()\n",
    "\n",
    "    def _compute_weights(self):\n",
    "        total = np.sum(self.class_counts) + 1e-6\n",
    "        freqs = self.class_counts / total\n",
    "        weights = 1.0 / (freqs + self.smoothing)\n",
    "        return weights / np.sum(weights)\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.weights.astype(np.float32)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.weights = self._compute_weights()\n",
    "\n",
    "#---PRINT CLASS IOU\n",
    "class PerClassIoU(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, ignore_classes=[255], name=\"per_class_iou\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_classes = tf.constant(ignore_classes, dtype=tf.int64)\n",
    "        self.valid_classes = tf.constant(\n",
    "            [i for i in range(num_classes) if i not in ignore_classes], dtype=tf.int64\n",
    "        )\n",
    "        self.intersections = self.add_weight(\n",
    "            name=\"intersections\", shape=(num_classes,), initializer=\"zeros\"\n",
    "        )\n",
    "        self.unions = self.add_weight(\n",
    "            name=\"unions\", shape=(num_classes,), initializer=\"zeros\"\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Convert from one-hot to class indices\n",
    "        y_true = tf.argmax(y_true, axis=-1)\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "        # Flatten\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "        y_pred = tf.reshape(y_pred, [-1])\n",
    "\n",
    "        # Filter out ignored classes (0 and 255)\n",
    "        ignore_mask = tf.reduce_any(tf.equal(tf.expand_dims(y_true, -1), self.ignore_classes), axis=-1)\n",
    "        valid_mask = tf.logical_not(ignore_mask)\n",
    "        y_true = tf.boolean_mask(y_true, valid_mask)\n",
    "        y_pred = tf.boolean_mask(y_pred, valid_mask)\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        cm = tf.math.confusion_matrix(\n",
    "            y_true, y_pred, num_classes=self.num_classes, dtype=tf.float32\n",
    "        )\n",
    "\n",
    "        # Diagonal: intersection\n",
    "        intersection = tf.linalg.diag_part(cm)\n",
    "        union = tf.reduce_sum(cm, axis=0) + tf.reduce_sum(cm, axis=1) - intersection\n",
    "        \n",
    "        #tf.print(\"Confusion matrix:\\n\", cm)\n",
    "        #tf.print(\"Intersection:\", intersection)\n",
    "        #tf.print(\"Union:\", union)\n",
    "\n",
    "        self.intersections.assign_add(intersection)\n",
    "        self.unions.assign_add(union)\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        # Return IoU for valid classes only\n",
    "        iou = self.intersections / (self.unions + 1e-7)\n",
    "        return tf.gather(iou, self.valid_classes)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.intersections.assign(tf.zeros_like(self.intersections))\n",
    "        self.unions.assign(tf.zeros_like(self.unions))\n",
    "\n",
    "class PrintPerClassIoU(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, metric, class_names=None):\n",
    "        super().__init__()\n",
    "        self.metric = metric\n",
    "        self.class_names = class_names or [f\"Class {i}\" for i in range(metric.num_classes)]\n",
    "\n",
    "    #def on_epoch_end(self, epoch, logs=None):\n",
    "    #    # Get current IoUs (as numpy array)\n",
    "    #    ious = self.metric.result().numpy()\n",
    "    #    valid_classes = self.metric.valid_classes.numpy()\n",
    "\n",
    "    #    print(f\"\\n🔍 Per-Class IoU at Epoch {epoch + 1}:\")\n",
    "    #    for i, class_id in enumerate(valid_classes):\n",
    "    #        class_name = self.class_names[class_id] if class_id < len(self.class_names) else f\"Class {class_id}\"\n",
    "    #        print(f\"  {class_name:>10}: {ious[i]:.4f}\")\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        ious = self.metric.intersections.numpy() / (self.metric.unions.numpy() + 1e-7)\n",
    "        valid_classes = self.metric.valid_classes.numpy()\n",
    "    \n",
    "        print(f\"\\n🔍 Per-Class IoU at Epoch {epoch + 1}:\")\n",
    "        for i, class_id in enumerate(valid_classes):\n",
    "            class_name = self.class_names[class_id] if class_id < len(self.class_names) else f\"Class {class_id}\"\n",
    "            print(f\"  {class_name:>10}: {ious[class_id]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "#---PRINT CLASS IOU---------\n",
    "\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "@register_keras_serializable()\n",
    "class CombinedLoss(tf.keras.losses.Loss):\n",
    "    #def __init__(self, get_weights, ignore_class=255, alpha=1.0, beta=1.0, name=\"combined_loss\", **kwargs):\n",
    "    def __init__(self, get_weights, ignore_class=255, alpha=tf.Variable(1.0), beta=tf.Variable(1.0), name=\"combined_loss\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.get_weights = get_weights\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.ignore_class = ignore_class\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        weights = tf.constant(self.get_weights(), dtype=tf.float32)\n",
    "        \n",
    "        # Convert one-hot to class indices to create mask\n",
    "        y_true_cls = tf.argmax(y_true, axis=-1)\n",
    "        mask = tf.not_equal(y_true_cls, self.ignore_class)\n",
    "\n",
    "        # Apply mask\n",
    "        mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "        # Compute weighted CE\n",
    "        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)  # shape: (batch, H, W)\n",
    "        pixel_weights = tf.reduce_sum(y_true * weights, axis=-1)       # shape: (batch, H, W)\n",
    "        weighted_ce = ce * pixel_weights * mask\n",
    "        loss_ce = tf.math.divide_no_nan(tf.reduce_sum(weighted_ce), tf.reduce_sum(mask))\n",
    "\n",
    "        # Compute masked Dice loss\n",
    "        intersection = tf.reduce_sum(y_true * y_pred * tf.expand_dims(mask, -1))\n",
    "        denominator = tf.reduce_sum((y_true + y_pred) * tf.expand_dims(mask, -1))\n",
    "        dice = (2. * intersection + 1e-7) / (denominator + 1e-7)\n",
    "        loss_dice = 1. - dice\n",
    "\n",
    "        return self.alpha * loss_ce + self.beta * loss_dice\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            #\"alpha\": self.alpha,\n",
    "            #\"beta\": self.beta,\n",
    "            \"alpha\": float(self.alpha.numpy()),\n",
    "            \"beta\": float(self.beta.numpy()),    \n",
    "            \"ignore_class\": self.ignore_class\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config, get_weights=None):\n",
    "        if get_weights is None:\n",
    "            raise ValueError(\"You must provide 'get_weights' when loading this loss, which cannot be deserialized automatically.\")\n",
    "        return cls(get_weights=get_weights, **config)\n",
    "\n",
    "\"\"\"\n",
    "class AdaptiveLossWeightCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, combined_loss, output_path=\"adaptive_loss_plot.png\",\n",
    "                 patience=3, cooldown=2, slope_scale=5.0, min_weight=0.2, max_weight=5.0):\n",
    "        super().__init__()\n",
    "        self.loss = combined_loss\n",
    "        self.output_path = output_path\n",
    "        self.patience = patience\n",
    "        self.cooldown = cooldown\n",
    "        self.slope_scale = slope_scale\n",
    "        self.min_weight = min_weight\n",
    "        self.max_weight = max_weight\n",
    "\n",
    "        self.best_iou = -np.inf\n",
    "        self.wait = 0\n",
    "        self.cooldown_counter = 0\n",
    "        self.val_ious = []\n",
    "\n",
    "        self.history = {\n",
    "            \"epoch\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_mean_iou\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "        }\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_iou = logs.get(\"val_mean_io_u\")\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if val_iou is None:\n",
    "            print(\"val_mean_io_u is not available in logs.\")\n",
    "            return\n",
    "\n",
    "        self.val_ious.append(val_iou)\n",
    "        self.history[\"epoch\"].append(epoch)\n",
    "        self.history[\"val_loss\"].append(val_loss)\n",
    "        self.history[\"val_mean_iou\"].append(val_iou)\n",
    "        self.history[\"alpha\"].append(float(self.loss.alpha.numpy()))\n",
    "        self.history[\"beta\"].append(float(self.loss.beta.numpy()))\n",
    "\n",
    "        if len(self.val_ious) <= self.patience:\n",
    "            return\n",
    "\n",
    "        x = np.arange(-self.patience, 1)\n",
    "        y = self.val_ious[-self.patience-1:]\n",
    "        slope = np.polyfit(x, y, 1)[0]\n",
    "\n",
    "        if self.cooldown_counter > 0:\n",
    "            self.cooldown_counter -= 1\n",
    "            return\n",
    "\n",
    "        if val_iou > self.best_iou:\n",
    "            self.best_iou = val_iou\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "\n",
    "        if self.wait >= self.patience:\n",
    "            delta = slope * self.slope_scale\n",
    "\n",
    "            new_alpha = float(self.loss.alpha.numpy()) * (1.0 + delta)\n",
    "            new_beta = float(self.loss.beta.numpy()) * (1.0 - delta)\n",
    "\n",
    "            new_alpha = np.clip(new_alpha, self.min_weight, self.max_weight)\n",
    "            new_beta = np.clip(new_beta, self.min_weight, self.max_weight)\n",
    "\n",
    "            self.loss.alpha.assign(new_alpha)\n",
    "            self.loss.beta.assign(new_beta)\n",
    "\n",
    "            print(f\"\\n[AdaptiveLoss] Epoch {epoch}: slope={slope:.4f}, adjusted α={new_alpha:.4f}, β={new_beta:.4f}\")\n",
    "\n",
    "            self.wait = 0\n",
    "            self.cooldown_counter = self.cooldown\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self.save_plot()\n",
    "\n",
    "    def save_plot(self):\n",
    "        history = self.history\n",
    "        if not history[\"epoch\"]:\n",
    "            print(\"No training history to plot.\")\n",
    "            return\n",
    "\n",
    "        plt.figure(figsize=(14, 5))\n",
    "\n",
    "        # Plot validation metrics\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history[\"epoch\"], history[\"val_mean_iou\"], label=\"Val Mean IoU\")\n",
    "        plt.plot(history[\"epoch\"], history[\"val_loss\"], label=\"Val Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Validation Metrics\")\n",
    "\n",
    "        # Plot alpha and beta\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history[\"epoch\"], history[\"alpha\"], label=\"Alpha (CE)\")\n",
    "        plt.plot(history[\"epoch\"], history[\"beta\"], label=\"Beta (Dice)\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.title(\"Adaptive Loss Weights\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Create directory if needed\n",
    "        os.makedirs(os.path.dirname(self.output_path), exist_ok=True)\n",
    "        plt.savefig(self.output_path)\n",
    "        plt.close()\n",
    "        print(f\"[AdaptiveLoss] Saved trend plot to {self.output_path}\")\n",
    "\"\"\"\n",
    "class AdaptiveLossCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        loss,\n",
    "        validation_data,\n",
    "        num_classes,\n",
    "        ignore_classes=[255],\n",
    "        csv_path=\"adaptive_loss_log.csv\",\n",
    "        patience=3,\n",
    "        slope_scale=1.8,\n",
    "        min_weight=0.1,\n",
    "        max_weight=0.9,\n",
    "        cooldown=2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.loss = loss\n",
    "        self.validation_data = validation_data\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_classes = ignore_classes\n",
    "        self.csv_path = csv_path\n",
    "        self.patience = patience\n",
    "        self.slope_scale = slope_scale\n",
    "        self.min_weight = min_weight\n",
    "        self.max_weight = max_weight\n",
    "        self.cooldown = cooldown\n",
    "        self.cooldown_counter = 0\n",
    "        self.wait = 0\n",
    "        self.best_iou = 0.0\n",
    "        self.val_ious = []\n",
    "        self.history = {\n",
    "            \"epoch\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_mean_iou\": [],\n",
    "            \"alpha\": [],\n",
    "            \"beta\": [],\n",
    "        }\n",
    "\n",
    "        self.per_class_iou_header = [f\"iou_class_{i}\" for i in range(self.num_classes)]\n",
    "\n",
    "        # Prepare CSV header\n",
    "        if not os.path.exists(csv_path):\n",
    "            with open(csv_path, mode=\"w\", newline=\"\") as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"epoch\", \"val_loss\", \"val_mean_iou\", \"alpha\", \"beta\"] + self.per_class_iou_header)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_iou = logs.get(\"val_mean_io_u\")\n",
    "        val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        if val_iou is None:\n",
    "            print(\"val_mean_io_u not found in logs.\")\n",
    "            return\n",
    "\n",
    "        alpha = float(self.loss.alpha.numpy())\n",
    "        beta = float(self.loss.beta.numpy())\n",
    "\n",
    "        # Compute per-class IoU\n",
    "        per_class_ious = self._compute_per_class_iou()\n",
    "\n",
    "        # Save logs to internal history\n",
    "        self.val_ious.append(val_iou)\n",
    "        self.history[\"epoch\"].append(epoch)\n",
    "        self.history[\"val_loss\"].append(val_loss)\n",
    "        self.history[\"val_mean_iou\"].append(val_iou)\n",
    "        self.history[\"alpha\"].append(alpha)\n",
    "        self.history[\"beta\"].append(beta)\n",
    "\n",
    "        # Save to CSV\n",
    "        with open(self.csv_path, mode=\"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([epoch, val_loss, val_iou, alpha, beta] + per_class_ious)\n",
    "\n",
    "        if len(self.val_ious) <= self.patience:\n",
    "            return\n",
    "\n",
    "        x = np.arange(-self.patience, 1)\n",
    "        y = self.val_ious[-self.patience - 1:]\n",
    "        slope = np.polyfit(x, y, 1)[0]\n",
    "\n",
    "        if self.cooldown_counter > 0:\n",
    "            self.cooldown_counter -= 1\n",
    "            return\n",
    "\n",
    "        if val_iou > self.best_iou:\n",
    "            self.best_iou = val_iou\n",
    "            self.wait = 0\n",
    "            return\n",
    "        else:\n",
    "            self.wait += 1\n",
    "\n",
    "        if self.wait >= self.patience:\n",
    "            delta = slope * self.slope_scale\n",
    "            current_alpha = alpha\n",
    "            current_beta = beta\n",
    "\n",
    "            alpha_a = np.clip(current_alpha * (1 + delta), self.min_weight, self.max_weight)\n",
    "            beta_a = np.clip(current_beta * (1 - delta), self.min_weight, self.max_weight)\n",
    "\n",
    "            alpha_b = np.clip(current_alpha * (1 - delta), self.min_weight, self.max_weight)\n",
    "            beta_b = np.clip(current_beta * (1 + delta), self.min_weight, self.max_weight)\n",
    "\n",
    "            print(f\"\\n[AdaptiveLoss] Epoch {epoch}: slope={slope:.4f}, trying both ↑α and ↓α\")\n",
    "\n",
    "            self.loss.alpha.assign(alpha_a)\n",
    "            self.loss.beta.assign(beta_a)\n",
    "            iou_a = self._evaluate_on_validation().get(\"val_mean_io_u\", 0)\n",
    "\n",
    "            self.loss.alpha.assign(alpha_b)\n",
    "            self.loss.beta.assign(beta_b)\n",
    "            iou_b = self._evaluate_on_validation().get(\"val_mean_io_u\", 0)\n",
    "\n",
    "            if iou_a >= iou_b:\n",
    "                self.loss.alpha.assign(alpha_a)\n",
    "                self.loss.beta.assign(beta_a)\n",
    "                print(f\"[AdaptiveLoss] ↑α chosen: α={alpha_a:.4f}, β={beta_a:.4f}, val_mIoU={iou_a:.4f}\")\n",
    "            else:\n",
    "                self.loss.alpha.assign(alpha_b)\n",
    "                self.loss.beta.assign(beta_b)\n",
    "                print(f\"[AdaptiveLoss] ↓α chosen: α={alpha_b:.4f}, β={beta_b:.4f}, val_mIoU={iou_b:.4f}\")\n",
    "\n",
    "            self.wait = 0\n",
    "            self.cooldown_counter = self.cooldown\n",
    "\n",
    "    def _evaluate_on_validation(self):\n",
    "        logs = self.model.evaluate(self.validation_data, return_dict=True, verbose=0)\n",
    "        return logs\n",
    "\n",
    "    def _compute_per_class_iou(self):\n",
    "        y_true_list = []\n",
    "        y_pred_list = []\n",
    "\n",
    "        for x_batch, y_true in self.validation_data:\n",
    "            y_pred = self.model.predict(x_batch, verbose=0)\n",
    "            y_true = tf.argmax(y_true, axis=-1)\n",
    "            y_pred = tf.argmax(y_pred, axis=-1)\n",
    "\n",
    "            y_true_list.append(tf.reshape(y_true, [-1]))\n",
    "            y_pred_list.append(tf.reshape(y_pred, [-1]))\n",
    "\n",
    "        y_true_flat = tf.concat(y_true_list, axis=0)\n",
    "        y_pred_flat = tf.concat(y_pred_list, axis=0)\n",
    "\n",
    "        per_class_ious = []\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            if i in self.ignore_classes:\n",
    "                per_class_ious.append(None)\n",
    "                continue\n",
    "\n",
    "            true_mask = tf.equal(y_true_flat, i)\n",
    "            pred_mask = tf.equal(y_pred_flat, i)\n",
    "            intersection = tf.reduce_sum(tf.cast(tf.logical_and(true_mask, pred_mask), tf.float32))\n",
    "            union = tf.reduce_sum(tf.cast(tf.logical_or(true_mask, pred_mask), tf.float32))\n",
    "\n",
    "            iou = (intersection / union).numpy() if union.numpy() > 0 else 0.0\n",
    "            per_class_ious.append(round(iou, 4))\n",
    "\n",
    "        return per_class_ious\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        self._plot_metrics()\n",
    "\n",
    "    def _plot_metrics(self):\n",
    "        epochs = self.history[\"epoch\"]\n",
    "\n",
    "        plt.figure(figsize=(14, 10))\n",
    "\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(epochs, self.history[\"val_mean_iou\"], marker=\"o\", color=\"green\")\n",
    "        plt.title(\"Validation Mean IoU\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"IoU\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(epochs, self.history[\"val_loss\"], marker=\"o\", color=\"red\")\n",
    "        plt.title(\"Validation Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(epochs, self.history[\"alpha\"], marker=\"o\", color=\"blue\")\n",
    "        plt.title(\"Alpha Over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Alpha\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(epochs, self.history[\"beta\"], marker=\"o\", color=\"orange\")\n",
    "        plt.title(\"Beta Over Epochs\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Beta\")\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"adaptive_loss_plot.png\", dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "# --> DECLARE THE INPUT IMAGE AND MASK IMAGE HERE\n",
    "\n",
    "predictedImage_path = '/home/dibakar88/Dibakar/InputTiff'  # Directory to save predicted masks\n",
    "model_path = '/home/dibakar88/Dibakar/unetpp_model.keras'\n",
    "\n",
    "PATCH_IMAGE_DIR = '/home/dibakar88/Dibakar/S2_24bands_Patch_aug'\n",
    "PATCH_MASK_DIR = '/home/dibakar88/Dibakar/S2_24bands_MaskPatch_aug'\n",
    "PATCH_IMAGE_TEST_DIR = '/home/dibakar88/Dibakar/S2_24bands_Patch_aug_val'\n",
    "PATCH_MASK_TEST_DIR = '/home/dibakar88/Dibakar/S2_24bands_MaskPatch_aug_val'\n",
    "\n",
    "# --> SET PARAMETERS OF MODEL HERE\n",
    "#ATTENTION\n",
    "# DO NOT CHANGE THE NAME OF THE VARIABLE, SINCE FUNCTIONS USE IT\n",
    "# Change normalized method of classification function based on the method of normalized when trained data\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 128, 128, 24  # Image dimensions and bands\n",
    "NUM_CLASSES = 2  # Number of categories\n",
    "IGNORE_CLASS = None  # or index to ignore\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "L2_FACTOR = 1e-4\n",
    "SEED = 42\n",
    "alphaC = 0.3  # alpha for cross entropy, beta for dice loss\n",
    "betaC = 0.7\n",
    "\n",
    "# --> SET PARAMETERS OF INPUT AND OUTPUT FOLDER PATH FOR IMAGE CLASSIFICATION HERE\n",
    "input_folder = '/home/dibakar88/Dibakar/InputTiff'\n",
    "predictedImage_path = '/home/dibakar88/Dibakar/result'\n",
    "\n",
    "\n",
    "train_imgs, train_masks = get_npy_filepaths(PATCH_IMAGE_DIR, PATCH_MASK_DIR)\n",
    "test_imgs, test_masks = get_npy_filepaths(PATCH_IMAGE_TEST_DIR, PATCH_MASK_TEST_DIR)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = create_dataset(train_imgs, train_masks, BATCH_SIZE, shuffle=True)\n",
    "val_dataset = create_dataset(test_imgs, test_masks, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "# Ajdust dynamic weight\n",
    "train_dataset_tracked, class_counts = track_class_counts(train_dataset, num_classes=NUM_CLASSES)\n",
    "dynamic_weights_cb = DynamicWeightsCallback(class_counts)\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"📂 Loading existing model without compiling...\")\n",
    "    model = tf.keras.models.load_model(\n",
    "        model_path,\n",
    "        custom_objects={'PerClassIoU': PerClassIoU},\n",
    "        compile=False  # do NOT compile yet\n",
    "    )\n",
    "    print(\"✅ Model loaded, now compiling with custom loss and metrics...\")\n",
    "    loss = CombinedLoss(get_weights=dynamic_weights_cb.get_weights, alpha=alphaC, beta=betaC)\n",
    "    #loss = CombinedLoss(get_weights=dynamic_weights_cb.get_weights, alpha=tf.Variable(alphaC), beta=tf.Variable(betaC))\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss,\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            PerClassIoU(num_classes=NUM_CLASSES)\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    print(\"🆕 No model found. Creating a new model...\")\n",
    "    model = unetpp_model_tf((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), NUM_CLASSES, L2_FACTOR)\n",
    "    #loss = CombinedLoss(get_weights=dynamic_weights_cb.get_weights, alpha=alpha, beta=beta)\n",
    "    loss = CombinedLoss(get_weights=dynamic_weights_cb.get_weights, alpha=tf.Variable(alphaC), beta=tf.Variable(betaC))\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=loss,\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES),\n",
    "            tf.keras.metrics.Precision(),\n",
    "            tf.keras.metrics.Recall(),\n",
    "            PerClassIoU(num_classes=NUM_CLASSES)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Stop training when validation loss doesn't improve for 10 epochs\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the best model based on validation loss\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,  # Set to True if you're saving only weights\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#Adjust alpha and beta of loss function\n",
    "adaptive_callback = AdaptiveLossCallback(\n",
    "    loss=loss,\n",
    "    validation_data=val_dataset,         # Your tf.data.Dataset for validation\n",
    "    num_classes=NUM_CLASSES,\n",
    "    ignore_classes=[255],\n",
    "    csv_path=predictedImage_path+'.csv',\n",
    "    patience=3,\n",
    "    slope_scale=1.3,\n",
    "    min_weight=0.1,\n",
    "    max_weight=0.9,\n",
    "    cooldown=3\n",
    ")\n",
    "\n",
    "#Learning rate\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    #callbacks=[checkpoint, early_stop]\n",
    "                    callbacks=[\n",
    "                           dynamic_weights_cb,  # if you're using dynamic weights\n",
    "                           early_stop_cb,\n",
    "                           checkpoint_cb,\n",
    "                           reduce_lr,\n",
    "                           adaptive_callback\n",
    "                           ]\n",
    "                    )\n",
    "\n",
    "\n",
    "print(\"Training model completed.\")\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(predictedImage_path, exist_ok=True)\n",
    "\n",
    "# Iterate through all image files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.tif', '.tiff')):  # You can add other image extensions if needed\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        print(f'Processing: {filename}')\n",
    "        # Classify the image\n",
    "        classified_map = classify_full_image(input_path, model)\n",
    "        # Save the result\n",
    "        outname = filename[:-4] + '_predicted.tif'\n",
    "        out_path = os.path.join(predictedImage_path, outname)\n",
    "        save_classified_geotiff(classified_map, reference_path=input_path, output_path=out_path)\n",
    "        print(f'Saved: {out_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
